# 浏览器使用get和post
这里特指非ajax请求，是html和浏览器诞生时在http协议里的get/post。浏览器通过get来获取css/图片/html页面/js,用post提交一个form表单,并得到一个结果网页
#### get
1. "读取"一个资源，反复读取不应该对访问数据有副作用，被称为幂等。（任意多次执行所产生的影响和一次执行的影响相同）
2. get可以对请求的数据做缓存，这个缓存可以做到浏览器本身上，代理上（如nginx）,serve端（用Etag,减少带宽消耗）
#### post
* 表单提交时，会发出post请求，让服务器做一件事，这件事有副作用，不幂等。
* 不幂等意味着不能多次执行，不能缓存。
* 表单重新提交浏览器也会弹出提示
#### 区别
1. 浏览器触发get请求只能由url触发，所以要带参数只能在url后面带上querystring。并不是http协议内使然
2. 浏览器的post提交都来自表单，表单数据会被编码到body里，浏览器通过application\x-www-form-urlencoded来传简单的数据
，还有通过multipart/form-data格式，后者会二进制的编码比前者高效，针对用于提交文件。
3. post提交表单时也可以带上querystring，只不过表单数据在body里。

# 接口中的GET和POST
* 通常指ajax,app的http client,java的commons-httpclient/okhttp或者是curl,postman之类的。此时的get/post不仅能在前后端交互中使用，也可以在后端和子服务间交互。
* 此类接口请求是没浏览器中这么多限制，只要符合http格式就行,甚至可以get带body,post用url带参，参数放Header里，body的格式也可以自己制定，但做前开发得好好讨论。
#### REST接口规范/风格
GET\POST\PUT\DELETE,它最佳推荐使用json格式，有嵌套结构和丰富的数据类型优势，但上传文件还是multipart/form-data格式更好。还有其他情况下像soap的get和post又会有所不同

# 安全性
get和post完全不是在浏览器地址栏看不看到的问题，因为http本身是明文协议，请求和返回每个byte都会在网路上明文传播。
#### 防止被窃数据
1. https，端端加密
2. 用私有网路
3. 其他加密协议（GB,SM）
* 除了金融和军队特殊机构，其他没多大必要自己搞个类似SSL的协议

# 编码
* http内的url只支持ASCII,percent encoding把特殊字符和中文编码了（浏览器地址可以看到中文，但发请求是是编码了）。但这种编码只管转字符，不管字符集编码，可能导致后端认不出来，所以有这类情况可以用ajax来传，ajax发出去的倒是能自己控制编码形式。不过现在基本utf-8大一统了。
* post请求有个content-type明确定义编码和body的格式。

# 请求优化
http请求分为请求头和请求体，通俗约定控制类信息放在请求头里，具体数据放在请求体里。这样服务器总是先解析请求体，然后再决定怎么对请求处理。
* 例如上传文件，利用http的Continued协议来做，请求头中包含文件名称，权限信息等。客户端先将所有请求头发给服务器，如果服务器验证通过，返回100-continue，客户端再把剩下的数据发给服务器。节省带宽，但代价会多个往返请求，如果刚好请求体数据不多，那就一次性全发。
* 客户端可以做个判断，大于1KB的先发请求体，否者就一次性全发

# 什么算请求体
从http协议角度，MEthod+url+Header都算请求头，后面都是体


http为啥区分头和体
* 对于HTTP代理
1. 支持转发规则，比如nginx先要解析请求头，拿到URL和Header才能决定怎么做（转发proxy_pass，重定向redirect，rewrite后重新判断……）
2. 需要用请求头的信息记录log。尽管请求体里的数据也可以记录，但一般只记录请求头的部分数据。
3. 如果代理规则不涉及到请求体，那么请求体就可以不用从内核态的page cache复制一份到用户态了，可以直接zero copy转发。这对于上传文件的场景极为有效。……
* 对于HTTP服务器
1. 可以通过请求头进行ACL控制，比如看看Athorization头里的数据是否能让认证通过
2. 可以做一些拦截，比如看到Content-Length里的数太大，或者Content-Type自己不支持，或者Accept要求的格式自己无法处理，就直接返回失败了。
3. 如果body的数据很大，利用Stream API，可以方便支持一块一块的处理数据，而不是一次性全部读取出来再操作，以至于占用大量内存。……

# 关于URl长度
* 所谓get数据长度限制，是指url的长度限制，http协议并没有对url长度限制，实际是由客户端/浏览器/服务端决定的
* 由于解析字符串代码需要分配内存，url这东西必须当作整体解析，所以得分配足够大的内存来解析。所以限制是好事
